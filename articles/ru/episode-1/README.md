![Image of this Article](https://raw.githubusercontent.com/totaki/graphql-learn/develop/articles/main.png)
# GraphQL и Python. Эпизод 1

В далекие далекие времена, когда сайты были многостраничными, а web-разработчики обязательно должны были знать PHP, css, html,
умные люди подумали и решили:
> *А зачем нам каждый раз перезагружать страницу, давайте просто будем отправлять запросы и полученные ответы вставлять прямо в разметку*.

И тут на свет появились первые SPA (Single Page Application), а вместе с ними ajax и REST API
. И в общем все хорошо, вырабатали стандарты, создали инструменты для разработки и документирования, такие как [Swagger](https://swagger.io/), и тут
в 2015 году Facebook представила на всеобщее обозрение, свой внтуренний инструмент **GraphQL** (разрабатываемый с 2012 года, [wiki](https://en.wikipedia.org/wiki/GraphQL)) для
работы с API. 

Когда я первый услышал о нем, полез сразу искать есть ли реализация на **python**, и наткнулся на библиотеку
 [Graphene](http://graphene-python.org/). К моему сожалению документация представляля из себя с десяток небольшмх разделов,
 и надо было больше читать саму [документацию GraphQL](http://graphql.org/learn/), а примеры со "Звёздными войнами"
 показались не совсем понятными. Попытка найти развернутые примеры на **python** закончилась провалом и 
 так родилась мысль разобраться в этом получше, а заодно написать небольшую статью, если быть
 точнее серию статей.

## Что такое GraphQL и какие проблемы он решает 
Это язык запросов разработанный компанией фейсбук, предпологается что это полноценная замена классическуму рест-апи.
Но рест-апи давно существует, появился теперь опенрест вместе со свагером, что делает разработку и документирование
проще и стандартизирование, так нахер использовать еще один новомодный инструмент? Погуглив интернет мы можем получить
узнать ```тут надо вставить с какого то ресурса плюсы графкл```. Когда я услышал и почитал документацию я выделил для себя
следующие преимущества

1.Помните:
```
/api/1/user/id
/api/2/user/id
/api/1/blogs/id
/api/1/blogs/id
....more
....more
and more
```

При добавление новых сущностей ваши апи начинают разрастаться, потом начинает не хватать метод гет, пут, пост, делете 
вы городите в текущих дополнительные апи. Вы поддерживаете версии апи. Кто-то может добавить уже существущий урль забыв
проверить, тогда вы получете хрень полную  

Вместо это вы получаете раз и навсегда
 ```
/graphql
```

2. Может так выйти что данные для одной сущности подтягиваются из разных источников, тогда вы обычно делаете прокси
сущность которые разрулит какие данные откуда брать. Графкл берет это на себя вам остается только получить данные

3. Помните:
```
func to_dict:
    ...
    
func to_public_dict:
    ...

func to_mobile_dict:
    ...
```

Вместо это вы просто указываете клиенту какие данные ему запросить,
```
query {
    user {
        id,
        name,
    }
}
```
А доступность полей может разрешить через middleware

4. Все конечо круто, гет-получить, пост-создать, пут-изменить, делите-удалить, но в итоге один хер получается каша

5. Помните:
```
Запросим пользователя
Получим айди его постов
Запросим посты пользотваеля
и т.д.
``` 

Вместо этого 
```
query {
    user(id: 1) {
        id,
        name,
        posts {
            title,
            link
        }
    }
}

```

Из минусов я пока вижу только что можно нагородить мегавложенный запрос, но для таких вещей есть фрагменты. О них тоже 
постараюсь расказать

## Где используется
Если говорить о том в каком компоненте программы, то только гуи-клиент -- сервер. Для микросерверсом он не подойдет, т.к.
есть определенный оверхед на сам размер запроса, во вторых нет надобности делать мегавложенность, микросервис должен в идеале
иметь 1 точку входа и делать что-то одно.
Если говорить о компаниях то это гитхаб фейсбук ```надо где-то найти еще``` 
## Что такое Relay, AppoloClient
Надо в гугль лезть, или просто забить на это


## Что нам для этог понадобится
1. Python 3
2. Tornado
3. Graphene
4. Docker вместе с docker-compose
5. GraphiQL
6. Nginx


Схема работы окружения для разработки будет следущая у нас поднимается nginx который проксирует
все на ноду, кроме запросов на /graphql который проксирует в наш бэкенд 


## Реализация на Python
На питон мы с вами будем реализовывать небольшую скрам доску. Базовые сущности у нас будут задачи, итерация и пользователи.

Задачи будут именть идентификатор, названия, описания, ответвсенного пользователя, итерация, статус и родителя
Пользователи в свою очередь будут иметь ник, задачи за которые пользователь отвественный

В первую очередь мы создадим наши абстракции 

Для начала мы сделаем хранилище для наших данных, я не буду использовать БД какую-либо, а сделаю просто классы которые
хранят в словаре с ключами int наши записи  


```python

class Record:
    
    def __init__(self, id_, type, data):
        pass

class Store:

    def __init__(self, *args, **kwargs):
        pass
       
    def get(self, id):
        pass
    
    def create(self, *args, **kwargs):
        pass
    
    def update(self, id, *args, **kwargs):
        pass
    
    def delete(self, id):
        pass
```

Теперь сделаем базовы классы:

```python
class User:
    
    """
    id: int
    name: str
    tasks: []
    """
    
    def get_tasks(self):
        pass
```

```python
class Iteration:

    """
    id: int
    start_date: datetime.date
    days: int
    tasks: []
    """
    def get_tasks(self):
        pass
    
    def get_stop_date(self):
        pass
```

```python
class Task:

    """
    id: int
    title: str
    description: str
    iteration: Iteration or None
    user: User or None
    parent: Task or None
    status: enum ['todo', 'inprogress', 'review', 'finish']
    """
```

Начнем с того что сделаем базу для нашей схемы
```python
class ScrumBoard:

    """
    backlog: [Task]
    dashboard: [Task]
    finish: [Task]
    """
    
    def get_backlog(self):
        pass
    
    def get_bashboard(self):
        pass
    
    def get_finish(self):
        pass
```

Будет у нас также 3 вида скопа, это бэклог (задачи без итерации), дашбоард (тут мы берем итерацию на текущий дату),
и финиш итерации которые на текущую дату завершенны


#  Попытка номер 2

В общем я попробовал пойти по обычному для себя пути, стал писать сначала пустые классы, что бы понять какие данные у меня
будут, потом стал писать для них атрибуты graphql и потом писать резолверы. Можно было бы отобразить это примерной схемой
## TODO: нарисовать схему
Но оказалось, что так у меня не получится, даже используя фабрики не получилось связать классы друг с другом, был вариант
переопределить базовые классы или сделать другие хаки, но по опыту могу сказать если возникает такое желание значит вы 
что-то делаете иначе. Потом я попробовал отобразить это в другой схемы, не классической, написал код который работал и делал
свою функцию, но опять же у меня осталось ощущение что это не совсем то как надо работать с graphql. И тут я решил пойти
3-им путем. Смоделить сначала юзерстори и отображение чтобы понять какие данные, в какой момент времени мне нужны.
И полчились следующие истори:

1. Первая страница, пользователь заходит и видит бэклог (список задач) и дашбоард (текущая итерация). В бэклог соотвественно мы должны видеть название задачи, её айди
и кому она назначена. В дашбоард у нас разбит на 4 статуса в каждом у нас список задач. Мы сможем с этой страницы добавлять 
задачи, открывать задачи и двигать задачи. Двигать задачи вперед мы можем как угодно, двигать назад со всем крофе финиш.
Притом с ревью двигается сразу на туду.
 
## Описание приложения, отличия от примера
## Написание схемы, тесты
## Написание endpoint, тесты
## IDE пример использованя


